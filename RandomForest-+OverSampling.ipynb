{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data 284807\n",
      "length of normal data 284315\n",
      "length of fraud  data 492\n"
     ]
    }
   ],
   "source": [
    "print(\"length of training data\",len(data))\n",
    "print(\"length of normal data\",len(data[data[\"Class\"]==0]))\n",
    "print(\"length of fraud  data\",len(data[data[\"Class\"]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_prepration(x): # preparing data for training and testing as we are going to use different data \n",
    "    #again and again so make a function\n",
    "    x_features= x.iloc[:,x.columns != \"Class\"]\n",
    "    x_labels=x.iloc[:,x.columns==\"Class\"]\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,test_size=0.3)\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data\n",
      "199364\n",
      "length of test data\n",
      "85443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Class'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X,data_test_X,data_train_y,data_test_y=data_prepration(data)\n",
    "data_train_X.columns\n",
    "data_train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data 199364\n",
      "length of normal data 199025\n",
      "length of fraud data 339\n"
     ]
    }
   ],
   "source": [
    "# Now we have a traing data\n",
    "data_train_X[\"Class\"]= data_train_y[\"Class\"] # combining class with original data\n",
    "data_train = data_train_X.copy() # for naming conevntion\n",
    "print(\"length of training data\",len(data_train))\n",
    "# Now make data set of normal transction from train data\n",
    "normal_data = data_train[data_train[\"Class\"]==0]\n",
    "print(\"length of normal data\",len(normal_data))\n",
    "fraud_data = data_train[data_train[\"Class\"]==1]\n",
    "print(\"length of fraud data\",len(fraud_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  322760\n",
      "Number of normal transcation in oversampled data 199025\n",
      "No.of fraud transcation 123735\n",
      "Proportion of Normal data in oversampled data is  0.6166346511339695\n",
      "Proportion of fraud data in oversampled data is  0.38336534886603046\n"
     ]
    }
   ],
   "source": [
    "# Now start oversampling of training data \n",
    "# means we will duplicate many times the value of fraud data\n",
    "for i in range (365):  # the number is choosen on basis of nnumber of fraud transaction\n",
    "    normal_data= normal_data.append(fraud_data)\n",
    "os_data = normal_data.copy() \n",
    "print(\"length of oversampled data is \",len(os_data))\n",
    "print(\"Number of normal transcation in oversampled data\",len(os_data[os_data[\"Class\"]==0]))\n",
    "print(\"No.of fraud transcation\",len(os_data[os_data[\"Class\"]==1]))\n",
    "print(\"Proportion of Normal data in oversampled data is \",len(os_data[os_data[\"Class\"]==0])/len(os_data))\n",
    "print(\"Proportion of fraud data in oversampled data is \",len(os_data[os_data[\"Class\"]==1])/len(os_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Normalized Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205059</th>\n",
       "      <td>-1.391305</td>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.297076</td>\n",
       "      <td>0.258042</td>\n",
       "      <td>-0.281132</td>\n",
       "      <td>0.424976</td>\n",
       "      <td>-0.583449</td>\n",
       "      <td>0.352227</td>\n",
       "      <td>-0.738469</td>\n",
       "      <td>0.930499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128380</td>\n",
       "      <td>0.750596</td>\n",
       "      <td>-0.277922</td>\n",
       "      <td>0.259807</td>\n",
       "      <td>-0.470461</td>\n",
       "      <td>-0.344876</td>\n",
       "      <td>-0.571860</td>\n",
       "      <td>0.377722</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.265213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228447</th>\n",
       "      <td>-0.536195</td>\n",
       "      <td>1.335664</td>\n",
       "      <td>-0.189138</td>\n",
       "      <td>-0.615918</td>\n",
       "      <td>0.163416</td>\n",
       "      <td>-1.134648</td>\n",
       "      <td>0.723638</td>\n",
       "      <td>0.170680</td>\n",
       "      <td>-0.175881</td>\n",
       "      <td>-0.358998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242243</td>\n",
       "      <td>-0.532338</td>\n",
       "      <td>0.104148</td>\n",
       "      <td>-0.005493</td>\n",
       "      <td>-0.372704</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>0.244282</td>\n",
       "      <td>0.085072</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.365868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70581</th>\n",
       "      <td>-0.865894</td>\n",
       "      <td>0.475476</td>\n",
       "      <td>1.351313</td>\n",
       "      <td>-0.933106</td>\n",
       "      <td>-0.513452</td>\n",
       "      <td>-0.340734</td>\n",
       "      <td>-0.036963</td>\n",
       "      <td>0.654538</td>\n",
       "      <td>-0.476130</td>\n",
       "      <td>-0.900145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053360</td>\n",
       "      <td>-0.202841</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.244310</td>\n",
       "      <td>-0.529880</td>\n",
       "      <td>0.608505</td>\n",
       "      <td>-0.183923</td>\n",
       "      <td>-0.090234</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.215534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92609</th>\n",
       "      <td>0.179736</td>\n",
       "      <td>-1.344464</td>\n",
       "      <td>-0.604072</td>\n",
       "      <td>1.420730</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.870044</td>\n",
       "      <td>-0.093957</td>\n",
       "      <td>-0.458721</td>\n",
       "      <td>-0.031717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340584</td>\n",
       "      <td>-0.180459</td>\n",
       "      <td>-0.571724</td>\n",
       "      <td>-0.281485</td>\n",
       "      <td>0.461669</td>\n",
       "      <td>-0.364694</td>\n",
       "      <td>-0.086315</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0</td>\n",
       "      <td>1.668433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170761</th>\n",
       "      <td>-0.075148</td>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.212873</td>\n",
       "      <td>-0.642528</td>\n",
       "      <td>0.558319</td>\n",
       "      <td>-1.016016</td>\n",
       "      <td>1.070621</td>\n",
       "      <td>-0.291876</td>\n",
       "      <td>-0.116072</td>\n",
       "      <td>-0.330003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242506</td>\n",
       "      <td>-0.516128</td>\n",
       "      <td>0.062934</td>\n",
       "      <td>-0.091145</td>\n",
       "      <td>-0.443438</td>\n",
       "      <td>0.131918</td>\n",
       "      <td>0.119782</td>\n",
       "      <td>0.094097</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.387187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "205059 -1.391305  0.116979  0.297076  0.258042 -0.281132  0.424976 -0.583449   \n",
       "228447 -0.536195  1.335664 -0.189138 -0.615918  0.163416 -1.134648  0.723638   \n",
       "70581  -0.865894  0.475476  1.351313 -0.933106 -0.513452 -0.340734 -0.036963   \n",
       "92609   0.179736 -1.344464 -0.604072  1.420730 -0.247348  0.124113  0.870044   \n",
       "170761 -0.075148  0.981137  0.212873 -0.642528  0.558319 -1.016016  1.070621   \n",
       "\n",
       "              V8        V9       V10        ...               V21       V22  \\\n",
       "205059  0.352227 -0.738469  0.930499        ...          0.128380  0.750596   \n",
       "228447  0.170680 -0.175881 -0.358998        ...         -0.242243 -0.532338   \n",
       "70581   0.654538 -0.476130 -0.900145        ...          0.053360 -0.202841   \n",
       "92609  -0.093957 -0.458721 -0.031717        ...          0.340584 -0.180459   \n",
       "170761 -0.291876 -0.116072 -0.330003        ...         -0.242506 -0.516128   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Class  \\\n",
       "205059 -0.277922  0.259807 -0.470461 -0.344876 -0.571860  0.377722      0   \n",
       "228447  0.104148 -0.005493 -0.372704  0.145606  0.244282  0.085072      0   \n",
       "70581   0.233645  0.244310 -0.529880  0.608505 -0.183923 -0.090234      0   \n",
       "92609  -0.571724 -0.281485  0.461669 -0.364694 -0.086315  0.090400      0   \n",
       "170761  0.062934 -0.091145 -0.443438  0.131918  0.119782  0.094097      0   \n",
       "\n",
       "        Normalized Amount  \n",
       "205059          -0.265213  \n",
       "228447          -0.365868  \n",
       "70581           -0.215534  \n",
       "92609            1.668433  \n",
       "170761          -0.387187  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before applying any model standerdize our data amount \n",
    "os_data[\"Normalized Amount\"] = StandardScaler().fit_transform(os_data['Amount'].values.reshape(-1, 1))\n",
    "os_data.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n",
    "os_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## first make a model function for modeling with confusion matrix\n",
    "def model(model,features_train,features_test,labels_train,labels_test):\n",
    "    clf= model\n",
    "    clf.fit(features_train,labels_train.values.ravel())\n",
    "    pred=clf.predict(features_test)\n",
    "    cnf_matrix=confusion_matrix(labels_test,pred)\n",
    "    print(\"the recall for this model is :\",cnf_matrix[1,1]/(cnf_matrix[1,1]+cnf_matrix[1,0]))\n",
    "    fig= plt.figure(figsize=(6,3))# to plot the graph\n",
    "    print(\"TP\",cnf_matrix[1,1,]) # no of fraud transaction which are predicted fraud\n",
    "    print(\"TN\",cnf_matrix[0,0]) # no. of normal transaction which are predited normal\n",
    "    print(\"FP\",cnf_matrix[0,1]) # no of normal transaction which are predicted fraud\n",
    "    print(\"FN\",cnf_matrix[1,0]) # no of fraud Transaction which are predicted normal\n",
    "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n",
    "    plt.title(\"Confusion_matrix\")\n",
    "    plt.xlabel(\"Predicted_class\")\n",
    "    plt.ylabel(\"Real class\")\n",
    "    plt.show()\n",
    "    print(\"\\n----------Classification Report------------------------------------\")\n",
    "    print(classification_report(labels_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data\n",
      "225932\n",
      "length of test data\n",
      "96828\n",
      "the recall for this model is : 1.0\n",
      "TP 37466\n",
      "TN 59358\n",
      "FP 4\n",
      "FN 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADhCAYAAADCg66ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVlOOcCbmeWUA7yZWU45wJuZ5dT/B034mRcyPfT3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d0339e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Classification Report------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     59362\n",
      "          1       1.00      1.00      1.00     37466\n",
      "\n",
      "avg / total       1.00      1.00      1.00     96828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now use this oversampled data for trainig the model and predict value for the test data that we created before\n",
    "# now let us try within the the oversampled data itself\n",
    "# for that we need to split our oversampled data into train and test\n",
    "# so call our function data Prepration with oversampled data\n",
    "os_train_X,os_test_X,os_train_y,os_test_y=data_prepration(os_data)\n",
    "clf= RandomForestClassifier(n_estimators=100)\n",
    "model(clf,os_train_X,os_test_X,os_train_y,os_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note:\n",
    "\n",
    "#since we have too many sample of same fraud data so may be the all which are present in train data are present in test data also so we can say it is over fitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
